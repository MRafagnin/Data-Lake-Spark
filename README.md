# Data Lake and ETL Pipeline for Sparkify

## Objective
> Build ETL pipeline that extracts data from S3, processes using Spark, and loads the data back into S3 as a set of dimensional tables for Sparkify Analytics Team

## Table of contents
* [Technologies](#technologies)
* [Launch](#launch)
* [Database Schema](#database-schema)
* [Datasets](#datasets)
* [Files in Repository](#files-in-repository)
* [IMPORTANT NOTES](#important-notes)

## Technologies
Project is created with:
- Jupyter Notebook
- Python 3
- AWS
- Spark

## Launch
- Run code line in `start.ipynb`

## Database Schema

#### Fact Table:
        
##### songplays - [records in log data associated with song plays]
- songplay_id, start_time, user_id, level, song_id, artist_id, session_id, location, user_agent
                    
#### Dimension Tables:

##### users - [users in the app]
- user_id, first_name, last_name, gender, level
            
##### songs - [songs in music database]
- song_id, title, artist_id, year, duration
            
##### artists - [artists in music database]
- artist_id, name, location, latitude, longitude

##### time - [timestamps of records in songplays broken down into specific units]
- start_time, hour, day, week, month, year, weekday


## Datasets

### Song Dataset
- Subset of data from [Million Song Dataset](https://labrosa.ee.columbia.edu/millionsong/)
- JSON files in S3 contain metadata about songs and artists
- Link: `s3://udacity-dend/song_data`

### Log Dataset
- JSON log files generated by [eventsim](https://github.com/Interana/eventsim) based on above dataset
- Link: `s3://udacity-dend/log_data`

## Files/Folder in Repository

- `start.ipynb` - executes and `etl.py`

- `etl.py` - reads data from S3, processes that data using Spark, and writes them back to S3

- `dl.cfg` - AWS credentials (fill accordantly)

- **data** - contains smaller datasets for testing purposes


## IMPORTANT NOTES:

> Add IAM role info to `dl.cfg`

> Reminder: Delete your cluster when finished (if applicable)

> Code references taken from the Knowledge platform